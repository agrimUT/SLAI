schedulers:
  - name: vllm
    scheduler: vllm
    batch_size: 128
  # - name: orca
  #   scheduler: orca
  #   batch_size: 8 # with higher batch size activation and kv cache memory blows up
  # - name: sarathi_1536
  #   scheduler: sarathi
  #   chunk_size: 1536
  #   batch_size: 128

traces:
  - name: chat
    trace_file: "./data/processed_traces/sharegpt_8k_filtered_stats_llama2_tokenizer.csv"
    max_seq_len: 8192
    num_requests: 16384
    start_qps: 2
  # - name: arxiv
  #   trace_file: "./data/processed_traces/arxiv_summarization_filtered_stats_llama2_tokenizer.csv"
  #   max_seq_len: 16384
  #   num_requests: 2048
  #   start_qps: 0.5

parallel_spec:
  - name: tp_1        
    tp_dimension: 1
    pp_dimension: 1

models:
  - name: llama-3.1-8b
    identifier: meta-llama/Llama-3.1-8B-Instruct
    parallel_specs: ["tp_1"]
    scheduler_specs: null # usee all
    traces: null # use all
