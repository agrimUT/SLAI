schedulers:
  # - name: vllm
  #   scheduler: vllm
  #   batch_size: 128
  # - name: orca
  #   scheduler: orca
  #   batch_size: 16 # with higher batch size activation and kv cache memory blows up
  # - name: sarathi_cs512_bs128
  #   scheduler: sarathi
  #   chunk_size: 512 # 2048 for relaxed 
  #   batch_size: 128
  #   capacity: 2
  - name: last_minute_cs512_bs128_offset_5_limittotaldecodes_128
    scheduler: last_minute
    token_budget: 512
    batch_size: 128
    offset: 5
    limit_total_decodes: 128
    time_between_tokens: 0.2 
    process_smallest_prefill: false
    capacity: 2 


traces:
  - name: chat
    trace_file: "/home/ab73456/sarathi-serve/data/processed_traces/sharegpt_8k_filtered_stats_llama2_tokenizer.csv"
    max_seq_len: 8192
    num_requests: 16384 # 4096 
    start_qps: 2
  # - name: arxiv
  #   trace_file: "/home/ab73456/sarathi-serve/data/processed_traces/arxiv_summarization_filtered_stats_llama2_tokenizer.csv"
  #   max_seq_len: 16384
  #   num_requests: 2048
  #   start_qps: 2

parallel_spec:
  - name: tp_1
    tp_dimension: 1
    pp_dimension: 1

models:
  - name: mistral-7b
    identifier: mistralai/Mistral-7B-Instruct-v0.2
    parallel_specs: ["tp_1"]
    scheduler_specs: null # usee all
    traces: null # use all
